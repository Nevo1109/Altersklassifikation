import torch
import torch.nn as nn
import cv2
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
import os
import time

class LiveCameraPredictor:
    def __init__(self, model_path="best_age_model.pth"):
        print("="*60)
        print(" LIVE KAMERA - ALTERS-KLASSIFIZIERUNG")
        print("="*60)
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"Device: {self.device}")
        
        self.img_size = 112
        self.age_groups = ["0-17", "18-29", "30-44", "45-59", "60+"]
        self.age_colors = [
            (0, 255, 0),    # Grün für jung
            (0, 200, 100),  # Hellgrün
            (0, 150, 255),  # Orange
            (0, 100, 255),  # Dunkelorange
            (0, 0, 255)     # Rot für alt
        ]
        
        # Modellarchitektur
        class SimpleAgeCNN(nn.Module):
            def __init__(self, num_classes=5):
                super(SimpleAgeCNN, self).__init__()
                self.features = nn.Sequential(
                    nn.Conv2d(3, 32, 3, padding=1),
                    nn.BatchNorm2d(32),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                    
                    nn.Conv2d(32, 64, 3, padding=1),
                    nn.BatchNorm2d(64),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                    
                    nn.Conv2d(64, 128, 3, padding=1),
                    nn.BatchNorm2d(128),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                    
                    nn.Conv2d(128, 256, 3, padding=1),
                    nn.BatchNorm2d(256),
                    nn.ReLU(),
                    nn.MaxPool2d(2),
                )
                
                self.classifier = nn.Sequential(
                    nn.Dropout(0.5),
                    nn.Linear(256 * 7 * 7, 512),
                    nn.ReLU(),
                    nn.Dropout(0.3),
                    nn.Linear(512, num_classes)
                )
            
            def forward(self, x):
                x = self.features(x)
                x = x.view(x.size(0), -1)
                x = self.classifier(x)
                return x
        
        # Modell laden
        self.model = SimpleAgeCNN(num_classes=5).to(self.device)
        
        if os.path.exists(model_path):
            print(f" Lade Modell: {model_path}")
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
            self.model_loaded = True
        else:
            print(f"  Modell nicht gefunden: {model_path}")
            print("   Starte DEMO-Modus ohne Vorhersage")
            self.model_loaded = False
        
        self.model.eval()
        
        # Transformation
        self.transform = transforms.Compose([
            transforms.Resize((self.img_size, self.img_size)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # Gesichtserkennung mit OpenCV
        print("Initialisiere Gesichtserkennung...")
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        
        # Kamera öffnen
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            print(" Kamera konnte nicht geöffnet werden!")
            self.cap = cv2.VideoCapture(1)  # Zweite Kamera versuchen
        
        if self.cap.isOpened():
            print(" Kamera bereit")
            print(f"\n TASTENBEFEHLE:")
            print("   SPACE - Bild speichern")
            print("   ESC   - Beenden")
            print("   S     - Statistiken anzeigen/ausblenden")
            print("   F     Gesichtserkennung ein/aus")
        else:
            print(" Keine Kamera gefunden!")
    
    def preprocess_face(self, face_image):
        """Gesicht für das Modell vorbereiten"""
        # Zu PIL konvertieren
        face_pil = Image.fromarray(face_image)
        
        # Transformieren
        face_tensor = self.transform(face_pil).unsqueeze(0).to(self.device)
        
        return face_tensor
    
    def predict_face(self, face_tensor):
        """Vorhersage für ein Gesicht"""
        with torch.no_grad():
            outputs = self.model(face_tensor)
            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
            predicted_class = outputs.argmax(1).item()
            confidence = probabilities[predicted_class].item() * 100
        
        return predicted_class, confidence, probabilities.cpu().numpy()
    
    def draw_prediction(self, frame, face_rect, prediction, confidence, probabilities):
        """Vorhersage auf Frame zeichnen"""
        x, y, w, h = face_rect
        
        # Altersgruppe und Farbe
        age_group = self.age_groups[prediction]
        color = self.age_colors[prediction]
        
        # Rechteck um Gesicht
        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
        
        # Hintergrund für Text
        text_bg_y = y - 30 if y > 40 else y + h + 10
        cv2.rectangle(frame, (x, text_bg_y-20), (x+200, text_bg_y+60), (0, 0, 0), -1)
        
        # Altersgruppe anzeigen
        text = f"{age_group} ({confidence:.0f}%)"
        cv2.putText(frame, text, (x+5, text_bg_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        # Wahrscheinlichkeitsbalken
        bar_width = 150
        bar_height = 10
        bar_start_x = x + 5
        bar_start_y = text_bg_y + 20
        
        # Gesamte Verteilung anzeigen
        for i, prob in enumerate(probabilities):
            bar_length = int(prob * bar_width)
            bar_y = bar_start_y + (i * (bar_height + 3))
            
            # Balken zeichnen
            cv2.rectangle(frame, 
                         (bar_start_x, bar_y),
                         (bar_start_x + bar_length, bar_y + bar_height),
                         self.age_colors[i], -1)
            
            # Beschriftung
            label = f"{self.age_groups[i]}: {prob*100:.0f}%"
            cv2.putText(frame, label, (bar_start_x + bar_width + 10, bar_y + bar_height-2),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        return frame
    
    def run(self):
        """Haupt-Loop für Live-Kamera"""
        if not self.cap.isOpened():
            print("Kamera nicht verfügbar. Beende...")
            return
        
        print("\n Starte Live-Kamera...")
        
        # Statistik-Variablen
        stats_enabled = True
        face_detection = True
        frame_count = 0
        fps = 0
        last_time = time.time()
        
        # Gesichtserkennung Statistiken
        face_stats = {age: 0 for age in self.age_groups}
        total_faces = 0
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                print(" Frame konnte nicht gelesen werden")
                break
            
            frame_count += 1
            
            # Spiegeln für natürlichen Look
            frame = cv2.flip(frame, 1)
            
            # Gesichter finden
            if face_detection:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                faces = self.face_cascade.detectMultiScale(
                    gray, 
                    scaleFactor=1.1, 
                    minNeighbors=5, 
                    minSize=(50, 50)
                )
                
                for (x, y, w, h) in faces:
                    # Gesicht extrahieren
                    face_img = frame[y:y+h, x:x+w]
                    
                    if face_img.size > 0 and self.model_loaded:
                        try:
                            # Vorverarbeiten
                            face_tensor = self.preprocess_face(face_img)
                            
                            # Vorhersage
                            prediction, confidence, probabilities = self.predict_face(face_tensor)
                            
                            # Statistiken aktualisieren
                            face_stats[self.age_groups[prediction]] += 1
                            total_faces += 1
                            
                            # Ergebnis zeichnen
                            frame = self.draw_prediction(
                                frame, (x, y, w, h), 
                                prediction, confidence, probabilities
                            )
                            
                        except Exception as e:
                            print(f"⚠  Fehler bei Vorhersage: {e}")
                            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)
                    
                    else:
                        # Nur Rechteck zeichnen (keine Vorhersage)
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 255), 2)
                        cv2.putText(frame, "Gesicht erkannt", (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # FPS berechnen
            current_time = time.time()
            if current_time - last_time >= 1.0:
                fps = frame_count
                frame_count = 0
                last_time = current_time
            
            # FPS anzeigen
            cv2.putText(frame, f"FPS: {fps}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # Modus anzeigen
            mode_text = "Live" if self.model_loaded else "DEMO"
            cv2.putText(frame, f"Modus: {mode_text}", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # Gesichtserkennung Status
            fd_text = "ON" if face_detection else "OFF"
            cv2.putText(frame, f"Gesichtserkennung: {fd_text}", (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # Statistiken anzeigen
            if stats_enabled and total_faces > 0:
                stats_y = 130
                cv2.putText(frame, "Statistiken:", (10, stats_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
                
                for i, age_group in enumerate(self.age_groups):
                    count = face_stats[age_group]
                    percentage = (count / total_faces * 100) if total_faces > 0 else 0
                    stats_y += 20
                    
                    cv2.putText(frame, 
                               f"{age_group}: {count} ({percentage:.1f}%)",
                               (10, stats_y),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, 
                               self.age_colors[i], 1)
            
            # Legende anzeigen
            legend_y = frame.shape[0] - 10
            cv2.putText(frame, "LEGENDE:", (10, legend_y - 100),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            
            for i, age_group in enumerate(self.age_groups):
                legend_y -= 20
                cv2.rectangle(frame, (10, legend_y-15), (25, legend_y), self.age_colors[i], -1)
                cv2.putText(frame, age_group, (30, legend_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # Frame anzeigen
            cv2.imshow('Live Alters-Klassifizierung', frame)
            
            # Tastatureingaben
            key = cv2.waitKey(1) & 0xFF
            
            if key == 27:  # ESC
                print("\n  Beende...")
                break
            
            elif key == 32:  # SPACE
                # Bild speichern
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                filename = f"screenshot_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                print(f" Bild gespeichert: {filename}")
            
            elif key == ord('s') or key == ord('S'):
                # Statistiken umschalten
                stats_enabled = not stats_enabled
                print(f"Statistiken: {'EIN' if stats_enabled else 'AUS'}")
            
            elif key == ord('f') or key == ord('F'):
                # Gesichtserkennung umschalten
                face_detection = not face_detection
                print(f"Gesichtserkennung: {'EIN' if face_detection else 'AUS'}")
            
            elif key == ord('c') or key == ord('C'):
                # Statistiken zurücksetzen
                face_stats = {age: 0 for age in self.age_groups}
                total_faces = 0
                print("Statistiken zurückgesetzt")
        
        # Aufräumen
        self.cap.release()
        cv2.destroyAllWindows()
        
        # Finale Statistiken
        if total_faces > 0:
            print(f"\n FINALE STATISTIKEN:")
            print('='*40)
            for age_group in self.age_groups:
                count = face_stats[age_group]
                percentage = (count / total_faces * 100)
                print(f"{age_group}: {count} Gesichter ({percentage:.1f}%)")
            print(f"Gesamt: {total_faces} Gesichter")

def main():
    # Prüfen ob OpenCV installiert ist
    try:
        import cv2
    except ImportError:
        print(" OpenCV nicht installiert!")
        print("Installiere mit: pip install opencv-python")
        return
    
    # Predictor starten
    predictor = LiveCameraPredictor("best_age_model.pth")
    
    # Haupt-Loop
    try:
        predictor.run()
    except KeyboardInterrupt:
        print("\n Abbruch durch Benutzer")
    except Exception as e:
        print(f" Fehler: {e}")
    finally:
        if hasattr(predictor, 'cap'):
            predictor.cap.release()
        cv2.destroyAllWindows()
    
    print("\n Programm beendet")

if __name__ == "__main__":
    main()
